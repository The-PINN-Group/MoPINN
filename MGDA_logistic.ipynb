{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinntorch import *\n",
    "from functools import partial\n",
    "from matplotlib.transforms import Bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution_log(x):\n",
    "    return 1/(1+torch.exp(-torch.Tensor(K*x)))\n",
    "\n",
    "# exact solution in NumPy: This one is needed for the loss function becasue somehow the tensor form does not work as of now.\n",
    "def exact_solution_log_np(x):\n",
    "    return 1/(1+np.exp(-K*x))\n",
    "\n",
    "def create_noisy_data(x, std_dev, noise_seed = 42):\n",
    "    exact = exact_solution_log(x)\n",
    "    torch.manual_seed(noise_seed)\n",
    "\n",
    "    return exact + torch.randn(exact.size())*std_dev \n",
    "\n",
    "def data_loss(model: PINN, data: torch.Tensor = None, x: torch.Tensor = None) -> torch.float:\n",
    "    # MSE loss \n",
    "    return (f(model, x) - data).pow(2).mean()\n",
    "\n",
    "def physics_loss(model: PINN, x: torch.Tensor = None) -> torch.float:\n",
    "    # define PDE loss\n",
    "    #x = generate_sample(20, (-1.0, 1.0))\n",
    "    pde_loss_pre = df(model, x) - K*f(model, x)*(1 - f(model, x))\n",
    "    pde_loss = pde_loss_pre.pow(2).mean()\n",
    "    \n",
    "    # define conditional losses (initial + boundary)\n",
    "    boundary_loss_right_pre = (f(model, at(+1.0)) - exact_solution_log_np(+1)) \n",
    "    boundary_loss_right = boundary_loss_right_pre.pow(2).mean()\n",
    "\n",
    "    # combine all losses\n",
    "    final_loss = pde_loss + boundary_loss_right\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "def total_loss(model: PINN, data: torch.Tensor = None, x: torch.Tensor= None) -> list:\n",
    "\n",
    "    \"\"\"lists both data and physics loss for mgda to work\"\"\"\n",
    "\n",
    "    loss_data = data_loss(model, data, x)\n",
    "\n",
    "    loss_physics = physics_loss(model, x)\n",
    "\n",
    "    return loss_data, loss_physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_training(settings, input_data, train_points, val_points):\n",
    "\n",
    "    L_p = []\n",
    "    L_d = []\n",
    "    L_VAL = []\n",
    "    LR = []\n",
    "    \n",
    "    models_trained = []\n",
    "\n",
    "    torch.manual_seed(settings['model_seed'])\n",
    "    for i in range(settings['population_size']):\n",
    "        print(i)\n",
    "        loss_fn = partial(total_loss,data = input_data, x=train_points)  # For each alpha we need a loss function with different alpha. \n",
    "             \n",
    "        model = PINN(1, 3, 9, 1)\n",
    "        \n",
    "        mgda = WeightMethods(\n",
    "            method=getattr(Moo_method, \"mgda\"),\n",
    "            n_tasks=2,\n",
    "            # normalization=config.moo_normalization, # mgda\n",
    "            device='cpu',\n",
    "        )\n",
    "\n",
    "        callbacks = [AllDataMonitor(\n",
    "            partial(data_loss, data=input_data, x=train_points), \n",
    "            partial(physics_loss, x=train_points), \n",
    "            partial(physics_loss, x=val_points))]\n",
    "        \n",
    "        trained_model = train_model(\n",
    "            model = model, \n",
    "            loss_fn=loss_fn,\n",
    "            mo_method=mgda,\n",
    "            max_epochs = settings['epochs'],\n",
    "            lr_decay=2e-2,\n",
    "            optimizer_fn = partial(torch.optim.Adam, lr=settings['start_learning_rate']),\n",
    "            epoch_callbacks = callbacks\n",
    "        )\n",
    "\n",
    "        L_p.append(np.array(callbacks[0].physics_history))\n",
    "        L_d.append(np.array(callbacks[0].data_history))\n",
    "        LR.append(np.array(callbacks[0].lr_history))\n",
    "        L_VAL.append(np.array(callbacks[0].val_history))\n",
    "        models_trained.append(trained_model)\n",
    "\n",
    "    return L_p, L_d, LR, L_VAL, models_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {}\n",
    "\n",
    "settings['n_data_points'] = 20\n",
    "settings['n_train_points'] = 20\n",
    "settings['n_val_points'] = 39\n",
    "settings['noise_level'] = 0.1\n",
    "settings['epochs'] = 10000\n",
    "settings['population_size'] = 50\n",
    "settings['noise_seed'] = 123\n",
    "settings['model_seed'] = 333\n",
    "settings['start_learning_rate'] = 0.01\n",
    "\n",
    "\n",
    "training_points = generate_grid((settings['n_train_points']), (-1.0,1.0))\n",
    "validation_points = generate_grid((settings['n_val_points']), (-1.0,1.0))\n",
    "\n",
    "data_noise = create_noisy_data(training_points, settings['noise_level'], noise_seed=settings['noise_seed'])\n",
    "\n",
    "Loss_physics, Loss_data, LR_evolution, Loss_val, models_trained = population_training(settings, data_noise, training_points, validation_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_pareto(points):\n",
    "    \"\"\"\n",
    "    Identify Pareto front indices in a set of points.\n",
    "    :param points: An array of points.\n",
    "    :return: Indices of points in the Pareto front.\n",
    "    \"\"\"\n",
    "    population_size = points.shape[0]\n",
    "    pareto_front = np.ones(population_size, dtype=bool)\n",
    "    for i in range(population_size):\n",
    "        for j in range(population_size):\n",
    "            if all(points[j] <= points[i]) and any(points[j] < points[i]):\n",
    "                pareto_front[i] = 0\n",
    "                break\n",
    "    return pareto_front\n",
    "\n",
    "def plot_pareto_front(\n",
    "    L_D,\n",
    "    L_P,\n",
    "    pareto_indices,\n",
    "    xtick_rotation=0,\n",
    "    file_name=\"pareto_plot\",\n",
    "    bbox_bounds=(0.1, -0.1, 5.2, 3.8),\n",
    "    left_margin=0.15,\n",
    "    bottom_margin=0.15,\n",
    "    x_lim=None,\n",
    "    y_lim=None,\n",
    "):\n",
    "    plt.figure(figsize=(5, 4))\n",
    "\n",
    "    # Plot all points\n",
    "    plt.scatter(L_D, L_P, color=\"gray\", label=\"Dominated\")  # Non-Pareto points in gray\n",
    "    # Plot Pareto points in a different color\n",
    "    plt.scatter(\n",
    "        np.array(L_D)[pareto_indices],\n",
    "        np.array(L_P)[pareto_indices],\n",
    "        color=\"blue\",\n",
    "        label=\"Non-Dominated\",\n",
    "    )  # Pareto points in blue\n",
    "\n",
    "    plt.ylabel(r\"$\\mathcal{L}_\\mathrm{PHYSICS}$\", loc=\"center\", fontsize=13)\n",
    "    plt.xlabel(r\"$\\mathcal{L}_\\mathrm{DATA}$\", loc=\"center\", fontsize=13)\n",
    "    plt.grid()\n",
    "\n",
    "    # Set axis to use scientific notation\n",
    "    plt.ticklabel_format(style=\"sci\", axis=\"both\", scilimits=(-2, 2))\n",
    "    plt.gca().xaxis.get_major_formatter().set_powerlimits((0, 1))\n",
    "    plt.gca().yaxis.get_major_formatter().set_powerlimits((0, 1))\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    # Optionally set x and y limits to zoom in\n",
    "    if x_lim is not None:\n",
    "        plt.xlim(x_lim)\n",
    "    if y_lim is not None:\n",
    "        plt.ylim(y_lim)\n",
    "\n",
    "    plt.subplots_adjust(left=left_margin, bottom=bottom_margin)\n",
    "\n",
    "    bbox_instance = Bbox.from_bounds(*bbox_bounds)\n",
    "    plt.xticks(rotation=xtick_rotation)\n",
    "\n",
    "    #plt.savefig(\"plots/\" + file_name + \".png\", dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "def find_last_threshold_index(physics, validation, threshold = 0.0):\n",
    "    over = (validation - physics) > threshold\n",
    "    reversed_arr = np.flipud(over)\n",
    "    index = len(over) - np.where(reversed_arr == False)[0][0] - 1\n",
    "    return index\n",
    "    \n",
    "def get_best_indices(physics, validation, threshold):\n",
    "    best_indices = []\n",
    "    for i in range(len(physics)):\n",
    "        best_indices.append(find_last_threshold_index(physics[i], validation[i], threshold))\n",
    "    return best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss_physics, Loss_data, LR_evolution, Loss_val, models_trained\n",
    "log_physics = np.array(Loss_physics)\n",
    "log_data = np.array(Loss_data)\n",
    "log_val = np.array(Loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_indices = get_best_indices(log_physics, log_val, 0.0)\n",
    "\n",
    "pareto_physics = [log_physics[i][best_indices[i]] for i in range(len(log_physics))]\n",
    "pareto_data = [log_data[i][best_indices[i]] for i in range(len(log_val))]\n",
    "\n",
    "# determine non-dominated points\n",
    "physics_data_points = np.array([(pareto_physics[i], pareto_data[i]) for i in range(len(pareto_physics))])\n",
    "pareto_indices = identify_pareto(physics_data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(pareto_data, pareto_physics, pareto_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
