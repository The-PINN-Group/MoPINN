{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinntorch import *\n",
    "from functools import partial\n",
    "from pinntorch.LBFGS import FullBatchLBFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution_log(x):\n",
    "    return 1/(1+torch.exp(-torch.Tensor(K*x)))\n",
    "\n",
    "# exact solution in NumPy: This one is needed for the loss function becasue somehow the tensor form does not work as of now.\n",
    "def exact_solution_log_np(x):\n",
    "    return 1/(1+np.exp(-K*x))\n",
    "\n",
    "def create_noisy_data(x, std_dev, noise_seed = 42):\n",
    "    exact = exact_solution_log(x)\n",
    "    torch.manual_seed(noise_seed)\n",
    "\n",
    "    return exact + torch.randn(exact.size())*std_dev \n",
    "\n",
    "def data_loss(model: PINN, data: torch.Tensor = None, x: torch.Tensor = None) -> torch.float:\n",
    "    # MSE loss \n",
    "    return (f(model, x) - data).pow(2).mean()\n",
    "\n",
    "def physics_loss(model: PINN, x: torch.Tensor = None) -> torch.float:\n",
    "    # define PDE loss\n",
    "    #x = generate_sample(20, (-1.0, 1.0))\n",
    "    pde_loss_pre = df(model, x) - K*f(model, x)*(1 - f(model, x))\n",
    "    pde_loss = pde_loss_pre.pow(2).mean()\n",
    "    \n",
    "    # define conditional losses (initial + boundary)\n",
    "    boundary_loss_right_pre = (f(model, at(+1.0)) - exact_solution_log_np(+1)) \n",
    "    boundary_loss_right = boundary_loss_right_pre.pow(2).mean()\n",
    "\n",
    "    # combine all losses\n",
    "    final_loss = pde_loss + boundary_loss_right\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "def generate_random_mask(size, num_true=5):\n",
    "    mask = torch.zeros(size, dtype=torch.bool)\n",
    "    indices = torch.randperm(size)[:num_true]\n",
    "    mask[indices] = True\n",
    "    return mask\n",
    "\n",
    "def total_loss(model: PINN, data: torch.Tensor = None, x: torch.Tensor= None) -> list:\n",
    "\n",
    "    \"\"\"adds the physics and the data loss with coefficients alpha and (1-alpha) respectively\"\"\"\n",
    "    #mask = generate_random_mask(20, 5)\n",
    "    #masked_data = data[mask]\n",
    "    #masked_x = x[mask]\n",
    "\n",
    "    loss_data = data_loss(model, data, x)\n",
    "\n",
    "    loss_physics = physics_loss(model, x)\n",
    "\n",
    "    return loss_data, loss_physics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValLRMonitor(EpochCallBack):\n",
    "    \"\"\"\n",
    "    Abstract base class for epoch callback objects.\n",
    "    \"\"\"\n",
    "    def __init__(self, validation_points):\n",
    "        self.val_points = validation_points\n",
    "        self.val_loss_fn = partial(physics_loss, x=self.val_points)\n",
    "\n",
    "    def prepare(self, max_epochs, model, loss_fn, optimizer):\n",
    "        self.val_history = []\n",
    "        self.lr_history = []\n",
    "\n",
    "    def process(self, epoch, model, loss_fn, optimizer, current_loss, extra_logs):\n",
    "        loss_val = self.val_loss_fn(model)\n",
    "        loss_physics_val = loss_val.detach().numpy()\n",
    "        self.lr_history.append(float(optimizer.param_groups[0][\"lr\"]))\n",
    "        self.val_history.append(loss_physics_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_training(settings, input_data, train_points, val_points):\n",
    "\n",
    "    L_p = []\n",
    "    L_d = []\n",
    "    L_VAL = []\n",
    "    LR = []\n",
    "    \n",
    "    models_trained = []\n",
    "\n",
    "    torch.manual_seed(settings['model_seed'])\n",
    "    for i in range(settings['population_size']):\n",
    "        print(i)\n",
    "        loss_fn = partial(total_loss,data = input_data, x=train_points)  # For each alpha we need a loss function with different alpha. \n",
    "             \n",
    "        model = PINN(1, 3, 9, 1)\n",
    "        \n",
    "        mgda = WeightMethods(\n",
    "            method=getattr(Moo_method, \"mgda\"),\n",
    "            n_tasks=2,\n",
    "            # normalization=config.moo_normalization, # mgda\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        callbacks = [TrainLossMonitor(), ValLRMonitor(val_points)]\n",
    "        trained_model = train_model(\n",
    "            model = model, \n",
    "            loss_fn=loss_fn,\n",
    "            #mo_method=mgda,\n",
    "            max_epochs = settings['epochs'],\n",
    "            lr_decay=1e-3,\n",
    "            optimizer_fn = partial(torch.optim.SGD, lr=settings['start_learning_rate']),\n",
    "            epoch_callbacks = callbacks\n",
    "        )\n",
    "\n",
    "\n",
    "        L_p.append(np.array(callbacks[0].loss_history[1]))\n",
    "        L_d.append(np.array(callbacks[0].loss_history[0]))\n",
    "        LR.append(np.array(callbacks[1].lr_history))\n",
    "        L_VAL.append(np.array(callbacks[1].val_history))\n",
    "        models_trained.append(trained_model)\n",
    "\n",
    "    return L_p, L_d, LR, L_VAL, models_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 0.1931, -0.0531,  0.2715, -0.1283,  0.4312, -0.0948, -0.7740,  0.2923,\n",
      "        -0.7242,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.4061, -0.5756, -0.2513, -0.1058,  0.7556, -0.6233,\n",
      "         0.3206,  0.6702,  0.2060,  0.0000,  0.2955, -0.0567, -0.1058,  0.5301,\n",
      "         0.2712, -0.1415,  0.0505, -0.4882,  0.0104,  0.5770,  0.4781,  0.3218,\n",
      "         0.2379, -0.4256,  0.2317,  0.4046, -0.2043, -0.0849,  0.2614,  0.3225,\n",
      "        -0.0299,  0.1104,  0.4705, -0.1131, -0.4947, -0.1415, -0.0039, -0.5565,\n",
      "         0.2833,  0.3858,  0.4362,  0.3946,  0.2032, -0.2013,  0.3049, -0.3904,\n",
      "        -0.1187, -0.3677, -0.0955,  0.4539, -0.2595, -0.4652, -0.1490, -0.1232,\n",
      "        -0.2446, -0.3536, -0.4240, -0.4896, -0.3478, -0.2339,  0.0349,  0.3865,\n",
      "        -0.1071, -0.5377,  0.2709,  0.0415,  0.0983,  0.1459, -0.4790,  0.4550,\n",
      "        -0.5112, -0.2801, -0.5719,  0.4733, -0.5769, -0.0804,  0.3464, -0.5504,\n",
      "         0.4967, -0.3262,  0.5173,  0.2982,  0.5393,  0.0481,  0.4925, -0.2799,\n",
      "        -0.1568, -0.3727, -0.2206,  0.5766, -0.1776,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4609, -0.1618,\n",
      "         0.1344, -0.2357,  0.2813, -0.2746, -0.0698, -0.3963, -0.5380,  0.1621,\n",
      "        -0.5756, -0.0376,  0.3574,  0.5332,  0.5034,  0.0061,  0.0451, -0.3127,\n",
      "         0.1747, -0.2769,  0.5671, -0.1071, -0.0288,  0.3538,  0.3104,  0.3580,\n",
      "        -0.1386, -0.3613,  0.2274, -0.1467, -0.4627, -0.2230, -0.0867, -0.0658,\n",
      "         0.1481, -0.2084, -0.3527, -0.3564, -0.2771, -0.4391, -0.4906, -0.5066,\n",
      "        -0.5302, -0.3934,  0.0152,  0.4669, -0.5127, -0.1853, -0.1452,  0.2691,\n",
      "        -0.4386,  0.3007, -0.0598, -0.2217,  0.5260,  0.4396, -0.2742,  0.2687,\n",
      "        -0.2585, -0.4381, -0.1471, -0.2873,  0.4942, -0.1312,  0.1678,  0.1848,\n",
      "         0.1727,  0.3489,  0.4881, -0.0140,  0.2515, -0.0234,  0.1138,  0.5053,\n",
      "        -0.1300,  0.2683,  0.2402,  0.4982,  0.4838,  0.3907,  0.3954,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "tensor([ 0.2043, -0.0279,  0.2873, -0.1456,  0.4340, -0.0992, -0.7592,  0.2995,\n",
      "        -0.7144,  0.0090,  0.0196,  0.0126, -0.0136,  0.0023, -0.0038,  0.0128,\n",
      "         0.0059,  0.0085,  0.3956, -0.5722, -0.2425, -0.1222,  0.7436, -0.6214,\n",
      "         0.3246,  0.6718,  0.2148,  0.0258,  0.2932, -0.0560, -0.1090,  0.5316,\n",
      "         0.2662, -0.1403,  0.0587, -0.4916,  0.0182,  0.5814,  0.4769,  0.3279,\n",
      "         0.2349, -0.4161,  0.2295,  0.3889, -0.1977, -0.0998,  0.2608,  0.3226,\n",
      "        -0.0308,  0.1108,  0.4691, -0.1128, -0.4924, -0.1424, -0.0017, -0.5575,\n",
      "         0.2836,  0.3844,  0.4369,  0.3924,  0.2037, -0.1977,  0.3034, -0.3870,\n",
      "        -0.1218, -0.3668, -0.0998,  0.4559, -0.2661, -0.4637, -0.1380, -0.1279,\n",
      "        -0.2341, -0.3553, -0.4236, -0.4920, -0.3467, -0.2375,  0.0357,  0.3925,\n",
      "        -0.1096, -0.5320,  0.2674,  0.0424,  0.0935,  0.1483, -0.4865,  0.4567,\n",
      "        -0.4988, -0.2853, -0.5601,  0.4710, -0.5763, -0.0836,  0.3479, -0.5554,\n",
      "         0.4978, -0.3180,  0.5138,  0.3060,  0.5412,  0.0476,  0.4952, -0.2811,\n",
      "        -0.1527, -0.3736, -0.2275,  0.5795, -0.1841, -0.0093,  0.0179, -0.0027,\n",
      "        -0.0043, -0.0124, -0.0068, -0.0144, -0.0094,  0.0082,  0.4597, -0.1660,\n",
      "         0.1407, -0.2291,  0.2823, -0.2768, -0.0642, -0.3969, -0.5302,  0.1639,\n",
      "        -0.5693, -0.0470,  0.3476,  0.5318,  0.5068, -0.0023,  0.0459, -0.3244,\n",
      "         0.1755, -0.2742,  0.5632, -0.1112, -0.0294,  0.3552,  0.3068,  0.3583,\n",
      "        -0.1435, -0.3610,  0.2284, -0.1482, -0.4642, -0.2232, -0.0862, -0.0671,\n",
      "         0.1482, -0.2102, -0.3548, -0.3641, -0.2657, -0.4271, -0.4889, -0.5107,\n",
      "        -0.5200, -0.3944,  0.0294,  0.4689, -0.5058, -0.1955, -0.1559,  0.2675,\n",
      "        -0.4349,  0.2916, -0.0590, -0.2345,  0.5251,  0.4361, -0.2690,  0.2742,\n",
      "        -0.2577, -0.4400, -0.1424, -0.2877,  0.5007, -0.1332,  0.1604,  0.1957,\n",
      "         0.1843,  0.3506,  0.4842, -0.0041,  0.2506, -0.0097,  0.1132,  0.5031,\n",
      "        -0.1268,  0.2717,  0.2407,  0.4970,  0.4867,  0.3904,  0.3994,  0.0099,\n",
      "        -0.0148, -0.0062, -0.0024,  0.0182, -0.0161,  0.0082,  0.0173,  0.0051])\n",
      "tensor([ 2.0879e-01, -1.7385e-02,  2.9398e-01, -1.5243e-01,  4.3558e-01,\n",
      "        -1.0079e-01, -7.5441e-01,  3.0270e-01, -7.1129e-01,  6.5483e-03,\n",
      "         1.5353e-02,  9.1871e-03, -1.0614e-02,  1.6325e-03, -2.5903e-03,\n",
      "         9.6563e-03,  4.0295e-03,  6.5239e-03,  3.9154e-01, -5.7186e-01,\n",
      "        -2.3952e-01, -1.2837e-01,  7.3981e-01, -6.2128e-01,  3.2678e-01,\n",
      "         6.7232e-01,  2.1795e-01,  2.0287e-02,  2.9220e-01, -5.5842e-02,\n",
      "        -1.1043e-01,  5.3230e-01,  2.6410e-01, -1.3985e-01,  6.2032e-02,\n",
      "        -4.9311e-01,  2.1334e-02,  5.8318e-01,  4.7657e-01,  3.3043e-01,\n",
      "         2.3367e-01, -4.1237e-01,  2.2865e-01,  3.8286e-01, -1.9508e-01,\n",
      "        -1.0552e-01,  2.6062e-01,  3.2267e-01, -3.1076e-02,  1.1093e-01,\n",
      "         4.6871e-01, -1.1270e-01, -4.9181e-01, -1.4268e-01, -1.1171e-03,\n",
      "        -5.5783e-01,  2.8365e-01,  3.8393e-01,  4.3712e-01,  3.9175e-01,\n",
      "         2.0385e-01, -1.9665e-01,  3.0295e-01, -3.8596e-01, -1.2306e-01,\n",
      "        -3.6658e-01, -1.0160e-01,  4.5682e-01, -2.6879e-01, -4.6303e-01,\n",
      "        -1.3370e-01, -1.2975e-01, -2.3003e-01, -3.5597e-01, -4.2344e-01,\n",
      "        -4.9292e-01, -3.4625e-01, -2.3895e-01,  3.6032e-02,  3.9478e-01,\n",
      "        -1.1057e-01, -5.2983e-01,  2.6603e-01,  4.2666e-02,  9.1569e-02,\n",
      "         1.4922e-01, -4.8933e-01,  4.5735e-01, -4.9423e-01, -2.8734e-01,\n",
      "        -5.5576e-01,  4.7000e-01, -5.7613e-01, -8.4962e-02,  3.4860e-01,\n",
      "        -5.5737e-01,  4.9827e-01, -3.1480e-01,  5.1243e-01,  3.0899e-01,\n",
      "         5.4205e-01,  4.7386e-02,  4.9629e-01, -2.8171e-01, -1.5101e-01,\n",
      "        -3.7403e-01, -2.3023e-01,  5.8067e-01, -1.8670e-01, -7.4148e-03,\n",
      "         1.4042e-02, -2.2662e-03, -3.5267e-03, -9.9120e-03, -5.3230e-03,\n",
      "        -1.1352e-02, -7.3677e-03,  5.5736e-03,  4.5916e-01, -1.6749e-01,\n",
      "         1.4302e-01, -2.2664e-01,  2.8248e-01, -2.7782e-01, -6.2214e-02,\n",
      "        -3.9718e-01, -5.2718e-01,  1.6473e-01, -5.6705e-01, -5.0670e-02,\n",
      "         3.4371e-01,  5.3145e-01,  5.0832e-01, -5.3994e-03,  4.6382e-02,\n",
      "        -3.2909e-01,  1.7582e-01, -2.7329e-01,  5.6165e-01, -1.1282e-01,\n",
      "        -2.9496e-02,  3.5587e-01,  3.0555e-01,  3.5853e-01, -1.4546e-01,\n",
      "        -3.6087e-01,  2.2882e-01, -1.4883e-01, -4.6494e-01, -2.2326e-01,\n",
      "        -8.5900e-02, -6.7675e-02,  1.4831e-01, -2.1109e-01, -3.5589e-01,\n",
      "        -3.6686e-01, -2.6110e-01, -4.2233e-01, -4.8849e-01, -5.1259e-01,\n",
      "        -5.1614e-01, -3.9503e-01,  3.5259e-02,  4.6980e-01, -5.0337e-01,\n",
      "        -1.9953e-01, -1.6010e-01,  2.6715e-01, -4.3328e-01,  2.8816e-01,\n",
      "        -5.8436e-02, -2.3961e-01,  5.2459e-01,  4.3483e-01, -2.6694e-01,\n",
      "         2.7633e-01, -2.5756e-01, -4.4083e-01, -1.4068e-01, -2.8799e-01,\n",
      "         5.0335e-01, -1.3425e-01,  1.5770e-01,  2.0009e-01,  1.8880e-01,\n",
      "         3.5093e-01,  4.8237e-01, -4.7299e-04,  2.5000e-01, -4.1019e-03,\n",
      "         1.1293e-01,  5.0230e-01, -1.2543e-01,  2.7306e-01,  2.4078e-01,\n",
      "         4.9647e-01,  4.8786e-01,  3.9026e-01,  4.0114e-01,  7.7538e-03,\n",
      "        -1.1625e-02, -4.9614e-03, -1.7345e-03,  1.4402e-02, -1.2626e-02,\n",
      "         6.3562e-03,  1.3572e-02,  3.9563e-03])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Repositories\\MoPINN\\pinntorch\\_training.py:130: RuntimeWarning: No multi-objective optimization method (mo_method) was set, despite defining multiple losses. Training will continue with the sum of the losses!\n",
      "  warnings.warn(\"No multi-objective optimization method (mo_method) was set, despite defining multiple losses. Training will continue with the sum of the losses!\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "settings = {}\n",
    "alphas = 1-torch.logspace(start=-2, end=0.0, steps=20, base=80)\n",
    "\n",
    "settings['n_data_points'] = 20\n",
    "settings['n_train_points'] = 20\n",
    "settings['n_val_points'] = 39\n",
    "settings['noise_level'] = 0.1\n",
    "settings['epochs'] = 3\n",
    "settings['population_size'] = 1\n",
    "settings['noise_seed'] = 123\n",
    "settings['model_seed'] = 333\n",
    "\n",
    "training_points = generate_grid((settings['n_train_points']), (-1.0,1.0))\n",
    "validation_points = generate_grid((settings['n_val_points']), (-1.0,1.0))\n",
    "\n",
    "data_noise = create_noisy_data(training_points, settings['noise_level'], noise_seed=settings['noise_seed'])\n",
    "\n",
    "settings['start_learning_rate'] = 0.003\n",
    "learning_rate = settings['start_learning_rate']\n",
    "epochs = settings['epochs']\n",
    "\n",
    "def custom_color_normalize(value):\n",
    "    return value**80\n",
    "\n",
    "#until = [9342, 5509, 5686, 6044, 6874, 8023, 9543, 8622, 2639, 2799, 3227, 3876, 128, 594, 169, 253, 410, 521, 2051, 49999]\n",
    "\n",
    "Loss_physics, Loss_data, LR_evolution, Loss_val, models_trained = population_training(settings, data_noise, training_points, validation_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings\n",
      "input_data\n",
      "loss_data\n",
      "loss_physics\n",
      "LR\n",
      "loss_val\n"
     ]
    }
   ],
   "source": [
    "run_name = 'mgda_lbfgs'\n",
    "\n",
    "result_dict = {\n",
    "    \"settings\" : settings,\n",
    "    \"input_data\": data_noise.detach().cpu().numpy(),\n",
    "    \"loss_data\": Loss_data,\n",
    "    \"loss_physics\": Loss_physics,\n",
    "    \"LR\": LR_evolution,\n",
    "    \"loss_val\": Loss_val\n",
    "}\n",
    "    \n",
    "path = create_run_folder(run_name)\n",
    "save_dictionary(path, run_name, result_dict)\n",
    "save_models(path, models_trained)\n",
    "\n",
    "#print(data_noise.shape)\n",
    "#save_results(run_name, settings, data_noise, Loss_data, Loss_physics, LR_evolution, Loss_val, models_trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
