{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinntorch import *\n",
    "from functools import partial\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib\n",
    "from matplotlib.transforms import Bbox\n",
    "\n",
    "# use GPU for faster training\n",
    "#torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "#device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1.0\n",
    "L = 5.0\n",
    "T = 12.5\n",
    "\n",
    "X_DOMAIN = (0.0, L)\n",
    "T_DOMAIN = (0.0, T)\n",
    "\n",
    "def exact_solution(x, t):\n",
    "    return torch.sin(torch.pi*x/L)*torch.exp(-k*((torch.pi**2)/(L**2))*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us first define some book keeping plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(x, t, data, grid_shape):\n",
    "    z = data\n",
    "    color_map = cm.winter\n",
    "    x = x.cpu().detach().numpy().reshape(grid_shape)\n",
    "    t = t.cpu().detach().numpy().reshape(grid_shape)\n",
    "    z = z.cpu().detach().numpy().reshape(grid_shape)\n",
    "\n",
    "    fig, ax = plt.subplots(subplot_kw=dict(projection='3d'))\n",
    "    ax.set(xlabel='x (location)', ylabel='t (time)', zlabel='function value')\n",
    "\n",
    "    ls = LightSource(270, 45)\n",
    "\n",
    "    surf = ax.plot_surface(x, t, z, cmap=color_map, linewidth=0, antialiased=False, shade=False)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "\n",
    "def plot_heatmap(x, t, data, grid_shape):\n",
    "    z = data\n",
    "    color_map = plt.cm.winter\n",
    "    x = x.cpu().detach().numpy().reshape(grid_shape)\n",
    "    t = t.cpu().detach().numpy().reshape(grid_shape)\n",
    "    z = z.cpu().detach().numpy().reshape(grid_shape)\n",
    "    print(z)\n",
    "    print((x.min(), x.max(), t.min(), t.max()))\n",
    "\n",
    "    plt.imshow(z, cmap=color_map, aspect='auto', origin='upper', extent=(t.min(), t.max(), x.min(), x.max()))\n",
    "    plt.colorbar(label='Function Value')\n",
    "    plt.xlabel('t (time)')\n",
    "    plt.ylabel('x (location)')\n",
    "    plt.title('Heat Map of Function')\n",
    "    plt.show()\n",
    "\n",
    "def plot_pareto_front(L_D, L_P, data_color, cmap = 'virdis'):\n",
    "    \n",
    "    plt.scatter(L_D, L_P, c=data_color.detach().numpy(), cmap='viridis')\n",
    "    \n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(r' $α$ Values')\n",
    "\n",
    "    plt.xlabel(r\"data loss ($L_d$)\")\n",
    "    plt.ylabel(r\"physics loss ($L_p$)\")\n",
    "    plt.title(\"Multi-objective optimization L = $α.L_d + (1-α)L_p$\")\n",
    "\n",
    "    #plt.savefig(\"heat_pareto_unstructured.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loss(model: nn.Module, data: torch.Tensor = None, x: torch.Tensor = None, t:torch.Tensor = None) -> torch.float:\n",
    "    \"\"\"\"Caculates the data loss\"\"\"\n",
    "    u_n = f(model, x, t) # evaluating the model\n",
    "    # MSE loss \n",
    "    diff = u_n - data    # u_exact + gaussian noise \n",
    "    \n",
    "    loss = diff.pow(2).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def physics_loss(\n",
    "    model: nn.Module, x: torch.Tensor = None, t: torch.Tensor = None\n",
    ") -> torch.float:\n",
    "\n",
    "    pde_loss_pre = df(model, x, t, wrt=1, order=1) - k*df(model, x, t, wrt=0, order=2)\n",
    "    pde_loss = pde_loss_pre.pow(2).mean()\n",
    "    \n",
    "\n",
    "    t_raw = unique_excluding(t, 0.)\n",
    "    x_left_boundary = fill_like(t_raw, 0.)\n",
    "    x_right_boundary = fill_like(t_raw, L)\n",
    "    x_raw = unique_excluding(x)\n",
    "    t_zero = fill_like(x_raw, 0.)\n",
    "\n",
    "    # dirichlet boundary conditions.  \n",
    "    boundary_left = f(model, x_left_boundary, t_raw).pow(2).mean()\n",
    "    boundary_right = f(model, x_right_boundary, t_raw).pow(2).mean()\n",
    "    boundary_loss = boundary_left + boundary_right\n",
    "\n",
    "    # initial\n",
    "    initial_loss_pre = f(model, x_raw, t_zero) - torch.sin(np.pi/L * x_raw).reshape(-1, 1)\n",
    "    initial_loss = initial_loss_pre.pow(2).mean()\n",
    "    \n",
    "    # together\n",
    "    conditional_loss = boundary_loss + initial_loss\n",
    "    \n",
    "    final_loss = pde_loss + conditional_loss\n",
    "    return final_loss\n",
    "\n",
    "def val_loss(\n",
    "    model: nn.Module, x: torch.Tensor, t: torch.Tensor) -> torch.float:\n",
    "\n",
    "    pde_loss_pre = df(model, x, t, wrt=1, order=1) - k*df(model, x, t, wrt=0, order=2)\n",
    "    pde_loss = pde_loss_pre.pow(2).mean()\n",
    "    \n",
    "    return pde_loss\n",
    "\n",
    "def total_loss(model: nn.Module, data: torch.Tensor, x_data: torch.Tensor, t_data: torch.Tensor, x_physics: torch.Tensor, t_physics: torch.Tensor, alpha: torch.float) -> torch.float:\n",
    "\n",
    "    loss_data = data_loss(model, data, x_data, t_data)\n",
    "\n",
    "    loss_physics = physics_loss(model, x_physics, t_physics)\n",
    "\n",
    "    total = alpha*loss_data + (1 - alpha)* loss_physics \n",
    "    \n",
    "    return total  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noisy_data(std_dev, exact_soln):\n",
    "\n",
    "    \"\"\"adds gaussian noise to the data\"\"\"\n",
    "\n",
    "    return exact_soln + torch.randn(exact_soln.shape)*std_dev "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_d, t_train_d = generate_grid((20,20), domain=(X_DOMAIN, T_DOMAIN))\n",
    "x_train_p, t_train_p = generate_grid((20,20), domain=(X_DOMAIN, T_DOMAIN))\n",
    "x_val, t_val = generate_grid((39,39), domain=(X_DOMAIN, T_DOMAIN))\n",
    "x_plot, t_plot = generate_grid((200,200), domain=(X_DOMAIN, T_DOMAIN))\n",
    "\n",
    "exact_soln = exact_solution(x_train_d, t_train_d)\n",
    "\n",
    "plot_solution = exact_solution(x_plot, t_plot)\n",
    "plot_heatmap(x_plot, t_plot, plot_solution, grid_shape=(200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = 1-torch.logspace(start=-2, end=0.0, steps=20, base=80)\n",
    "\n",
    "settings = {}\n",
    "settings['seed'] = 11373\n",
    "settings['alphas'] = alphas.cpu()\n",
    "settings['n_train_points'] = 20\n",
    "settings['n_val_points'] = 39\n",
    "settings['noise_level'] = 0.1\n",
    "settings['start_learning_rate'] = 0.003\n",
    "settings['epochs'] = 10000\n",
    "\n",
    "torch.manual_seed(settings['seed'])\n",
    "\n",
    "input_data = create_noisy_data(settings['noise_level'], exact_soln)\n",
    "\n",
    "plot_data(x_train_d, t_train_d, input_data, (20, 20))\n",
    "\n",
    "def custom_color_normalize(value):\n",
    "    return value**80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_training(alphas, input_data, x_train_d, t_train_d, x_train_p, t_train_p, x_val, t_val):\n",
    "    L_p = []\n",
    "    L_d = []\n",
    "    L_VAL = []\n",
    "    LR = []\n",
    "    \n",
    "    models_trained = []\n",
    "    for i, alpha in enumerate(alphas):\n",
    "        print(\"i:\", i, \"alpha:\", alpha)\n",
    "        \n",
    "        loss_fn = partial(total_loss,data = input_data, x_data=x_train_d, t_data=t_train_d, x_physics=x_train_p, t_physics=t_train_p, alpha = alpha)\n",
    "        \n",
    "        torch.manual_seed(7245)\n",
    "        \n",
    "        model = PINN(2, 4, 50, 1)\n",
    "        model.to(device)\n",
    "      \n",
    "        callbacks = [AllDataMonitor(\n",
    "            partial(data_loss, data=input_data, x=x_train_d, t=t_train_d), \n",
    "            partial(physics_loss, x=x_train_p, t=t_train_p), \n",
    "            partial(val_loss, x=x_val, t=t_val))]\n",
    "        \n",
    "        trained_model = train_model(\n",
    "        model = model, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer_fn=partial(torch.optim.Adam, lr=settings['start_learning_rate']),\n",
    "        max_epochs = settings['epochs'],\n",
    "        lr_decay = 2e-2,\n",
    "        epoch_callbacks = callbacks)\n",
    "\n",
    "        L_p.append(np.array(callbacks[0].physics_history))\n",
    "        L_d.append(np.array(callbacks[0].data_history))\n",
    "        LR.append(np.array(callbacks[0].lr_history))\n",
    "        L_VAL.append(np.array(callbacks[0].val_history))\n",
    "        models_trained.append(trained_model)\n",
    "\n",
    "    return L_p, L_d, LR, L_VAL, models_trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with exact solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_p, Loss_d, LR, Loss_VAL, models_trained = scalar_training(alphas, input_data, x_train_d, t_train_d, x_train_p, t_train_p, x_val, t_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_color_normalize(value):\n",
    "    return value**80\n",
    "\n",
    "def log_tick_formatter(val, pos):\n",
    "    if np.isclose(val**(1./80.), show_alphas_scaled).any():\n",
    "        if val == 1.0:\n",
    "            return f\"({val**(1./80.):.5f})\"\n",
    "        return f\"{val**(1./80.):.5f}\"\n",
    "    return \"\"\n",
    "    \n",
    "def tick_formatter(val, pos):\n",
    "    skip_indices = [1,2,3,5,15,16,17,18,19,20]  # Adjust the indices you want to skip\n",
    "    if pos in skip_indices:\n",
    "        return ''\n",
    "    elif pos == 1:\n",
    "        return '('+str(1.0)+')'\n",
    "    return alphas[pos]\n",
    "    \n",
    "def find_last_threshold_index(physics, validation, threshold = 0.0):\n",
    "    over = (validation - physics) > threshold\n",
    "    reversed_arr = np.flipud(over)\n",
    "    index = len(over) - np.where(reversed_arr == False)[0][0] - 1\n",
    "    return index\n",
    "\n",
    "def plot_pareto_front(L_D, L_P, data_color):\n",
    "    cmap = matplotlib.colormaps['jet']\n",
    "    plt.figure(figsize=(5,4))\n",
    "    low_noise_points = plt.scatter(L_D, L_P, c=custom_color_normalize(data_color), cmap=cmap) \n",
    "    # Add colorbar for the z values\n",
    "    cbar_lown = plt.colorbar(low_noise_points, ticks=custom_color_normalize(np.concatenate(([1.0], data_color))), format=FuncFormatter(tick_formatter))\n",
    "\n",
    "    cbar_lown.set_label(r' $α$ (log scaled)', fontsize=13)\n",
    "    \n",
    "    plt.ylabel(r\"$\\mathcal{L}_\\mathrm{PHYSICS}$\", loc='center', fontsize=13)\n",
    "    plt.xlabel(r\"$\\mathcal{L}_\\mathrm{DATA}$\", loc='center', fontsize=13)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    bbox_instance = Bbox.from_bounds(0.1, -0.1, 5.2, 3.8)\n",
    "\n",
    "    #plt.savefig('../plots/heat_L5k1_pareto_normal.png', dpi=600, bbox_inches=bbox_instance)\n",
    "    plt.show()\n",
    "\n",
    "def get_best_indices(physics, validation, threshold):\n",
    "    best_indices = []\n",
    "    for i in range(len(physics)):\n",
    "        best_indices.append(find_last_threshold_index(physics[i], validation[i], threshold))\n",
    "    return best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_data = np.array(Loss_d)\n",
    "heat_physics = np.array(Loss_p)\n",
    "heat_val = np.array(Loss_VAL) \n",
    "alphas = np.array(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the converged/not overfitted indices for every model via threshold between physics and validation\n",
    "\n",
    "best_indices = get_best_indices(heat_physics, heat_val, 0.0)\n",
    "\n",
    "pareto_physics = [heat_physics[i][best_indices[i]] for i in range(len(heat_physics))]\n",
    "pareto_data = [heat_data[i][best_indices[i]] for i in range(len(heat_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(pareto_data, pareto_physics, alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinngpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
