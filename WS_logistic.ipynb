{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinntorch import *\n",
    "from functools import partial\n",
    "import matplotlib\n",
    "from matplotlib.transforms import Bbox\n",
    "from matplotlib.ticker import FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_solution_log(x):\n",
    "    return 1/(1+torch.exp(-torch.Tensor(K*x)))\n",
    "\n",
    "# exact solution in NumPy: This one is needed for the loss function becasue somehow the tensor form does not work as of now.\n",
    "def exact_solution_log_np(x):\n",
    "    return 1/(1+np.exp(-K*x))\n",
    "\n",
    "def create_noisy_data(x, std_dev, noise_seed = 42):\n",
    "    exact = exact_solution_log(x)\n",
    "    torch.manual_seed(noise_seed)\n",
    "    \n",
    "    return exact + torch.randn(exact.size())*std_dev \n",
    "\n",
    "def data_loss(model: PINN, data: torch.Tensor = None, x: torch.Tensor = None) -> torch.float:\n",
    "    return (f(model, x) - data).pow(2).mean()\n",
    "\n",
    "def physics_loss(model: PINN, x: torch.Tensor = None) -> torch.float:\n",
    "    # define PDE loss\n",
    "    pde_loss_pre = df(model, x) - K*f(model, x)*(1 - f(model, x))\n",
    "    pde_loss = pde_loss_pre.pow(2).mean()\n",
    "    \n",
    "    # define conditional losses (initial + boundary)\n",
    "    boundary_loss_right_pre = (f(model, at(+1.0)) - exact_solution_log_np(+1)) \n",
    "    boundary_loss_right = boundary_loss_right_pre.pow(2).mean()\n",
    "\n",
    "    # combine all losses\n",
    "    final_loss = pde_loss + boundary_loss_right\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "def total_loss(model: PINN, data: torch.Tensor = None, x: torch.Tensor= None, alpha: torch.float= None) -> list:\n",
    "\n",
    "    \"\"\"adds the physics and the data loss with coefficients alpha and (1-alpha) respectively\"\"\"\n",
    "\n",
    "    loss_data = data_loss(model,data, x)\n",
    "\n",
    "    loss_physics = physics_loss(model, x)\n",
    "\n",
    "    return alpha*loss_data + (1 - alpha)* loss_physics\n",
    "\n",
    "def custom_color_normalize(value):\n",
    "    return value**80\n",
    "    \n",
    "\n",
    "def find_last_threshold_index(physics, validation, threshold = 0.0):\n",
    "    over = (validation - physics) > threshold\n",
    "    reversed_arr = np.flipud(over)\n",
    "    index = len(over) - np.where(reversed_arr == False)[0][0] - 1\n",
    "    return index\n",
    "\n",
    "def get_best_indices(physics, validation, threshold = 0.0):\n",
    "    best_indices = []\n",
    "    for i in range(len(physics)):\n",
    "        best_indices.append(find_last_threshold_index(physics[i], validation[i], threshold))\n",
    "    return best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalar_training(settings, input_data, train_points, val_points):\n",
    "\n",
    "    L_p = []\n",
    "    L_d = []\n",
    "    L_VAL = []\n",
    "    LR = []\n",
    "    \n",
    "    models_trained = []\n",
    "    for i, alpha in enumerate(settings['alphas']):\n",
    "        print(\"i:\", i, \"alpha:\", alpha)\n",
    "        loss_fn = partial(total_loss,data = input_data, x=train_points, alpha = alpha)  # For each alpha we need a loss function with different alpha. \n",
    "             \n",
    "        torch.manual_seed(settings['model_seed'])\n",
    "        model = PINN(1, 3, 9, 1)\n",
    "\n",
    "\n",
    "        callbacks = [AllDataMonitor(\n",
    "            partial(data_loss, data=input_data, x=train_points), \n",
    "            partial(physics_loss, x=train_points), \n",
    "            partial(physics_loss, x=val_points))]\n",
    "\n",
    "\n",
    "        trained_model = train_model(\n",
    "            model = model, \n",
    "            loss_fn=loss_fn,\n",
    "            max_epochs = settings['epochs'],\n",
    "            lr_decay=2e-2,\n",
    "            optimizer_fn = partial(torch.optim.Adam, lr=settings['start_learning_rate']),\n",
    "            epoch_callbacks = callbacks\n",
    "        )\n",
    "\n",
    "        L_p.append(np.array(callbacks[0].physics_history))\n",
    "        L_d.append(np.array(callbacks[0].data_history))\n",
    "        LR.append(np.array(callbacks[0].lr_history))\n",
    "        L_VAL.append(np.array(callbacks[0].val_history))\n",
    "        models_trained.append(trained_model)\n",
    "\n",
    "    return L_p, L_d, LR, L_VAL, models_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = {}\n",
    "\n",
    "# create alpha list\n",
    "alphas = 1-torch.logspace(start=-2, end=0.0, steps=20, base=80)\n",
    "\n",
    "\n",
    "settings['n_train_points'] = 20\n",
    "settings['n_val_points'] = 39\n",
    "settings['noise_level'] = 0.1\n",
    "settings['epochs'] = 10000\n",
    "settings['alphas'] = alphas.cpu()\n",
    "settings['noise_seed'] = 123\n",
    "settings['model_seed'] = 111\n",
    "settings['start_learning_rate'] = 0.01\n",
    "\n",
    "training_points = generate_grid((settings['n_train_points']), (-1.0,1.0))\n",
    "validation_points = generate_grid((settings['n_val_points']), (-1.0,1.0))\n",
    "\n",
    "data_noise = create_noisy_data(training_points, settings['noise_level'], noise_seed=settings['noise_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_physics, Loss_data, LR_evolution, Loss_val, models_trained = scalar_training(settings, data_noise, training_points, validation_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tick_formatter(val, pos):\n",
    "    skip_indices = [1,2,3,5,15,16,17,18,19,20]  # alpha indices to skip showing\n",
    "    if pos in skip_indices:\n",
    "        return ''\n",
    "    elif pos == 1:\n",
    "        return '('+str(1.0)+')'\n",
    "    return alphas[pos]\n",
    "\n",
    "def plot_pareto_front(L_D, L_P, data_color, xtick_rotation=0, file_name='log_pareto', bbox_bounds = (0.1, -0.1, 5.2, 3.8)):\n",
    "    cmap = matplotlib.colormaps['jet']\n",
    "    plt.figure(figsize=(5,4))\n",
    "    low_noise_points = plt.scatter(L_D, L_P, c=custom_color_normalize(data_color), cmap=cmap)  # Use 'viridis' colormap, but you can choose any other\n",
    "    # Add colorbar for the z values\n",
    "    cbar_lown = plt.colorbar(low_noise_points, ticks=custom_color_normalize(np.concatenate(([1.0], data_color))), format=FuncFormatter(tick_formatter))\n",
    "\n",
    "    cbar_lown.set_label(r' $Î±$ (log scaled)', fontsize=13)\n",
    "    \n",
    "    plt.ylabel(r\"$\\mathcal{L}_\\mathrm{PHYSICS}$\", loc='center', fontsize=13)\n",
    "    plt.xlabel(r\"$\\mathcal{L}_\\mathrm{DATA}$\", loc='center', fontsize=13)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    bbox_instance = Bbox.from_bounds(*bbox_bounds)\n",
    "    plt.xticks(rotation=xtick_rotation)\n",
    "\n",
    "    plt.savefig(file_name+'.png', dpi=600, bbox_inches=bbox_instance)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.array(alphas)\n",
    "\n",
    "log_data = np.array(Loss_data) \n",
    "log_physics = np.array(Loss_physics) \n",
    "log_val = np.array(Loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the converged/not overfitted indices for every model via threshold between physics and validation\n",
    "best_indices = get_best_indices(log_physics, log_val, 0.001)\n",
    "\n",
    "# extract data loss and physics loss according to the indices\n",
    "log_best_data = [log_data[i][best_indices[i]] for i in range(len(log_data))]\n",
    "log_best_physics = [log_physics[i][best_indices[i]] for i in range(len(log_physics))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pareto_front(log_best_data, log_best_physics, alphas, 0, 'log_best', (0.1, -0.1, 5.2, 3.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
